---
title: "Basic examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Basic examples}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, warning=FALSE, message=FALSE}
library(blendR)
```


```{r install-pkgs, warning=FALSE, message=FALSE, eval=FALSE, echo=FALSE}
if (!requireNamespace("survHEhmc")) remotes::install_github('giabaio/survHEhmc')
```

```{r, warning=FALSE, message=FALSE}
library(survHE)
library(INLA)
```

```{r limit-cores, echo=FALSE}
# R CMD check only allows a maximum of two cores
options(mc.cores=2)
inla.setOption(num.threads = 2)
```


## INLA piece-wise exponential and external knowledge

First load the package data and take a look.

```{r}
data("TA174_FCR", package = "blendR")
head(dat_FCR)
```

Next, fit the observed data with a piece-wise exponential model using INLA.

```{r}
# observed estimate
obs_Surv <- fit_inla_pw(data = dat_FCR,
                        cutpoints = seq(0, 180, by = 5))
```

For the external model first we create some synthetic data consistent with user-defined constraints as follows.

```{r}
# external estimate
data_sim <- ext_surv_sim(t_info = 144,
                         S_info = 0.05,
                         T_max = 180)
```

Then fit a gompertz model to this.

```{r}
ext_Surv <- fit.models(formula = Surv(time, event) ~ 1,
                       data = data_sim,
                       distr = "gompertz",
                       method = "hmc",
                       priors = list(gom = list(a_alpha = 0.1,
                                                b_alpha = 0.1)))
```

Lastly, we can run the blending step.

```{r}
blend_interv <- list(min = 48, max = 150)
beta_params <- list(alpha = 3, beta = 3)

ble_Surv <- blendsurv(obs_Surv, ext_Surv, blend_interv, beta_params)
```

We can visualise all of the curves.

```{r}
plot(ble_Surv)
```

## Two HMC survHE fits

In the same way as above we fit two survival curves and then blend them together.
In this case we use two exponential curves using the survHE package to fit them.

```{r}
obs_Surv2 <- fit.models(formula = Surv(death_t, death) ~ 1,
                        data = dat_FCR,
                        distr = "exponential",
                        method = "hmc")

ext_Surv2 <- fit.models(formula = Surv(time, event) ~ 1,
                       data = data_sim,
                       distr = "exponential",
                       method = "hmc")
```

```{r}
ble_Surv2 <- blendsurv(obs_Surv2, ext_Surv2, blend_interv, beta_params)

# kaplan-meier
km <- survfit(Surv(death_t, death) ~ 1, data = dat_FCR)

plot(ble_Surv2) +
  geom_line(aes(km$time, km$surv, colour = "Kaplan-Meier"),
            size = 1.25, linetype = "dashed")
```

## flexsurv frequentist background fit

The next example is for an HMC and frequentist survival model using the flexsurv package directly.

```{r}
obs_Surv3 <- fit.models(formula = Surv(death_t, death) ~ 1,
                        data = dat_FCR,
                        distr = "exponential",
                        method = "hmc")

ext_Surv3 <- flexsurv::flexsurvreg(formula = Surv(time, event) ~ 1,
                       data = data_sim,
                       dist = "gompertz")

ble_Surv3 <- blendsurv(obs_Surv3, ext_Surv3, blend_interv, beta_params)

plot(ble_Surv3)
```

<!-- TODO -->
## `{expertsurv}` background fit

The next example is using the [`{expertsurv}`](https://github.com/Philip-Cooney/expertsurv) package to fit the external model.

We can create the external survival curve using the penalised regression model.

```{r eval=FALSE}}
# if (!requireNamespace("expertsurv", quietly = TRUE)) 
#   remotes::install_github("Philip-Cooney/expertsurv")

library(expertsurv)

param_expert <- list()

# S = 0.05
param_expert[[1]] <- data.frame(dist = "norm",
                                wi = 1,
                                param1 = 0.2,
                                param2 = 0.05,
                                param3 = NA)

# S = 0
param_expert[[2]] <- data.frame(dist = "norm",
                                wi = 1,
                                param1 = 0.05,
                                param2 = 0.005,
                                param3 = NA)

timepoint_expert <- c(100, 180)

# dummy data
data <- data.frame(time =50, event = 0)

# don't provide any data so its all based on the prior
ext_Surv <- fit.models.expert(formula = Surv(time,event) ~ 1,
                              data = data,
                              distr = "gomp",
                              method = "hmc",
                              iter = 1000,
                              opinion_type = "survival",
                              times_expert = timepoint_expert, 
                              param_expert = param_expert)

plot(ext_Surv, add.km = T, t = seq(0:180), ci = TRUE)


##TODO: how to get confidence intervals? make.surv()?

# obs_Surv <- survHE::fit.models(formula = Surv(death_t, death) ~ 1,
#                        data = dat_FCR,
#                        distr = "exponential",
#                        method = "hmc")

bs_Surv <- flexsurv::flexsurvreg(formula = Surv(time, event) ~ 1,
                       data = data_sim,
                       dist = "exp")

ble_Surv <- blendsurv(obs_Surv, ext_Surv, blend_interv, beta_params)

plot(ble_Surv)
```

Alternatively, we could use the `{expertsurv}` functions to fit both the data and the external information together as intended in the `{expertsurv}` package.
However, to modify this so that it is similar to `{blendr}` we can choose variance of constraint as functions of the blending interval.


TODO...
## Using sample size formula

```{r}
# external estimate
data_sim <- ext_surv_sim(t_info = 100,
                         S_info = 0.05,
                         T_max = 180,
                         n = 100)
                         # n = 40)
```

```{r}
ext_Surv3 <- flexsurv::flexsurvreg(formula = Surv(time, event) ~ 1,
                       data = data_sim,
                       dist = "exp")
```

```{r}
plot(ext_Surv3)
summary(ext_Surv3)
```

median time of mean 46
median time of upper limit 60
0.5 = exp(-lambda t) so lambda = log(2)/t
which gives log(2)/46 = 0.015 and log(2)/60 = 0.012
a hazard ratio of 46/60 = 0.77

```{r}
# log-mean method
# https://shariq-mohammed.github.io/files/cbsa2019/2-power-and-sample-size.html
expLogMeanDeaths = function(Delta, alpha, pwr){
  z.alpha = qnorm(alpha, lower.tail=FALSE)
  z.beta = qnorm(1-pwr, lower.tail=FALSE)
  num = (z.alpha + z.beta)^2
  denom = (log(Delta))^2

  num/denom
}
```

```{r}
# one-sided test
expLogMeanDeaths(Delta = 0.77, alpha = 0.025, pwr = 0.8)
```


